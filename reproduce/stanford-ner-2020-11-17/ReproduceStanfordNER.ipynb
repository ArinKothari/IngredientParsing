{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67443d6c",
   "metadata": {},
   "source": [
    "# Ingredient Parser Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2a0ee0d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 cups all-purpose flour\n",
      "[('3', 'QUANTITY'), ('cups', 'UNIT'), ('all-purpose', 'NAME'), ('flour', 'NAME')]\n",
      "\n",
      "\n",
      "1 teaspoon nutmeg\n",
      "[('1', 'QUANTITY'), ('teaspoon', 'UNIT'), ('nutmeg', 'NAME')]\n",
      "\n",
      "\n",
      "1 teaspoon ground ginger\n",
      "[('1', 'QUANTITY'), ('teaspoon', 'UNIT'), ('ground', 'STATE'), ('ginger', 'NAME')]\n",
      "\n",
      "\n",
      "2 teaspoons cinnamon\n",
      "[('2', 'QUANTITY'), ('teaspoons', 'UNIT'), ('cinnamon', 'NAME')]\n",
      "\n",
      "\n",
      "1 teaspoon baking soda\n",
      "[('1', 'QUANTITY'), ('teaspoon', 'UNIT'), ('baking', 'NAME'), ('soda', 'NAME')]\n",
      "\n",
      "\n",
      "1 teaspoon salt\n",
      "[('1', 'QUANTITY'), ('teaspoon', 'UNIT'), ('salt', 'NAME')]\n",
      "\n",
      "\n",
      "1 cup chopped pecans\n",
      "[('1', 'QUANTITY'), ('cup', 'UNIT'), ('chopped', 'STATE'), ('pecans', 'NAME')]\n",
      "\n",
      "\n",
      "3 ripe bananas\n",
      "[('3', 'QUANTITY'), ('ripe', 'STATE'), ('bananas', 'NAME')]\n",
      "\n",
      "\n",
      "2 cups granulated sugar\n",
      "[('2', 'QUANTITY'), ('cups', 'UNIT'), ('granulated', 'STATE'), ('sugar', 'NAME')]\n",
      "\n",
      "\n",
      "1 20-ounce can of diced pineapple, drained\n",
      "[('1', 'QUANTITY'), ('20-ounce', 'UNIT'), ('can', 'UNIT'), ('of', 'O'), ('diced', 'STATE'), ('pineapple', 'NAME'), (',', 'O'), ('drained', 'STATE')]\n",
      "\n",
      "\n",
      "1 cup canola oil\n",
      "[('1', 'QUANTITY'), ('cup', 'UNIT'), ('canola', 'NAME'), ('oil', 'NAME')]\n",
      "\n",
      "\n",
      "3 large eggs\n",
      "[('3', 'QUANTITY'), ('large', 'SIZE'), ('eggs', 'NAME')]\n",
      "\n",
      "\n",
      "16 ounces cream cheese\n",
      "[('16', 'QUANTITY'), ('ounces', 'UNIT'), ('cream', 'NAME'), ('cheese', 'NAME')]\n",
      "\n",
      "\n",
      "4 ounces unsalted butter\n",
      "[('4', 'QUANTITY'), ('ounces', 'UNIT'), ('unsalted', 'STATE'), ('butter', 'NAME')]\n",
      "\n",
      "\n",
      "1 teaspoon vanilla extract\n",
      "[('1', 'QUANTITY'), ('teaspoon', 'UNIT'), ('vanilla', 'NAME'), ('extract', 'NAME')]\n",
      "\n",
      "\n",
      "½ teaspoon salt\n",
      "[('½', 'QUANTITY'), ('teaspoon', 'UNIT'), ('salt', 'NAME')]\n",
      "\n",
      "\n",
      "6 cups powdered sugar\n",
      "[('6', 'QUANTITY'), ('cups', 'UNIT'), ('powdered', 'STATE'), ('sugar', 'NAME')]\n",
      "\n",
      "\n",
      "½ cup chopped pecans, for decorating\n",
      "[('½', 'QUANTITY'), ('cup', 'UNIT'), ('chopped', 'STATE'), ('pecans', 'NAME'), (',', 'O'), ('for', 'O'), ('decorating', 'O')]\n",
      "\n",
      "\n",
      "9 tablespoons unsalted butter, at room temperature\n",
      "[('9', 'QUANTITY'), ('tablespoons', 'UNIT'), ('unsalted', 'STATE'), ('butter', 'NAME'), (',', 'O'), ('at', 'O'), ('room', 'O'), ('temperature', 'O')]\n",
      "\n",
      "\n",
      "1 cup plus 2 tablespoons sugar\n",
      "[('1', 'QUANTITY'), ('cup', 'UNIT'), ('plus', 'O'), ('2', 'QUANTITY'), ('tablespoons', 'UNIT'), ('sugar', 'NAME')]\n",
      "\n",
      "\n",
      "3  large eggs\n",
      "[('3', 'QUANTITY'), ('large', 'SIZE'), ('eggs', 'NAME')]\n",
      "\n",
      "\n",
      "1 ¼ cups all-purpose flour\n",
      "[('1', 'QUANTITY'), ('¼', 'QUANTITY'), ('cups', 'UNIT'), ('all-purpose', 'NAME'), ('flour', 'NAME')]\n",
      "\n",
      "\n",
      "1 pinch salt\n",
      "[('1', 'QUANTITY'), ('pinch', 'UNIT'), ('salt', 'NAME')]\n",
      "\n",
      "\n",
      "1 cup fresh ricotta\n",
      "[('1', 'QUANTITY'), ('cup', 'UNIT'), ('fresh', 'DF'), ('ricotta', 'NAME')]\n",
      "\n",
      "\n",
      "Zest of 1 lemon\n",
      "[('Zest', 'NAME'), ('of', 'O'), ('1', 'QUANTITY'), ('lemon', 'NAME')]\n",
      "\n",
      "\n",
      "1 tablespoon baking powder\n",
      "[('1', 'QUANTITY'), ('tablespoon', 'UNIT'), ('baking', 'NAME'), ('powder', 'NAME')]\n",
      "\n",
      "\n",
      "1  apple, peeled and grated (should yield about 1 cup)\n",
      "[('1', 'QUANTITY'), ('apple', 'NAME'), (',', 'O'), ('peeled', 'STATE'), ('and', 'O'), ('grated', 'STATE'), ('(', 'O'), ('should', 'O'), ('yield', 'O'), ('about', 'O'), ('1', 'O'), ('cup', 'O'), (')', 'O')]\n",
      "\n",
      "\n",
      "Confectioners' sugar for serving\n",
      "[('Confectioners', 'NAME'), (\"'\", 'O'), ('sugar', 'NAME'), ('for', 'O'), ('serving', 'O')]\n",
      "\n",
      "\n",
      "1/2 large sweet red onion, thinly sliced\n",
      "[('12', 'QUANTITY'), ('large', 'SIZE'), ('sweet', 'NAME'), ('red', 'NAME'), ('onion', 'NAME'), (',', 'O'), ('thinly', 'O'), ('sliced', 'STATE')]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ingredients = [\n",
    "    \"3 cups all-purpose flour\",\n",
    "    \"1 teaspoon nutmeg\",\n",
    "    \"1 teaspoon ground ginger\",\n",
    "    \"2 teaspoons cinnamon\",\n",
    "    \"1 teaspoon baking soda\",\n",
    "    \"1 teaspoon salt\",\n",
    "    \"1 cup chopped pecans\",\n",
    "    \"3 ripe bananas\",\n",
    "    \"2 cups granulated sugar\",\n",
    "    \"1 20-ounce can of diced pineapple, drained\",\n",
    "    \"1 cup canola oil\",\n",
    "    \"3 large eggs\",\n",
    "    \"16 ounces cream cheese\",\n",
    "    \"4 ounces unsalted butter\",\n",
    "    \"1 teaspoon vanilla extract\",\n",
    "    \"½ teaspoon salt\",\n",
    "    \"6 cups powdered sugar\",\n",
    "    \"½ cup chopped pecans, for decorating\",\n",
    "    \"9 tablespoons unsalted butter, at room temperature\",\n",
    "    \"1 cup plus 2 tablespoons sugar\",\n",
    "    \"3  large eggs\",\n",
    "    \"1 ¼ cups all-purpose flour\",\n",
    "    \"1 pinch salt\",\n",
    "    \"1 cup fresh ricotta\",\n",
    "    \"Zest of 1 lemon\",\n",
    "    \"1 tablespoon baking powder\",\n",
    "    \"1  apple, peeled and grated (should yield about 1 cup)\",\n",
    "    \"Confectioners' sugar for serving\",\n",
    "    '1/2 large sweet red onion, thinly sliced'\n",
    "]\n",
    "\n",
    "import nltk\n",
    "from nltk.tag.stanford import StanfordNERTagger\n",
    "\n",
    "sentence = u\"Twenty miles east of Reno, Nev., \" \\\n",
    "    \"where packs of wild mustangs roam free through \" \\\n",
    "    \"the parched landscape, Tesla Gigafactory 1 \" \\\n",
    "    \"sprawls near Interstate 80.\"\n",
    "\n",
    "jar = './stanford-ner.jar'\n",
    "model = './trained_ar_gk.ser.gz'\n",
    "\n",
    "# Prepare NER tagger with english model\n",
    "ner_tagger = StanfordNERTagger(model, jar, encoding='utf8')\n",
    "\n",
    "for sample in ingredients:\n",
    "    # Tokenize: Split sentence into words\n",
    "    print(sample)\n",
    "    words = nltk.word_tokenize(sample)\n",
    "\n",
    "    # Run NER tagger on words\n",
    "    print(ner_tagger.tag(words))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f308971d",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38be7d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples(file):\n",
    "    label2id = {'DF': 0, 'NAME': 1, 'O': 2, 'QUANTITY': 3, 'SIZE': 4, 'STATE': 5, 'TEMP': 6, 'UNIT': 7}\n",
    "    samples = []\n",
    "    label_types = set()\n",
    "    \n",
    "    with open(file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        label = []\n",
    "        sentence = []\n",
    "        for line in lines:\n",
    "            line = line.strip().strip('\\n')\n",
    "            if not line:\n",
    "                if label and sentence:\n",
    "                    sample = {'text': \" \".join(sentence), 'labels': label}\n",
    "                    samples.append(sample)\n",
    "                label = []\n",
    "                sentence = []\n",
    "            else:\n",
    "                token, tag = line.split('\\t')\n",
    "#                 token = convert_number(token)\n",
    "                token = token.lower()\n",
    "                if len(token.split()) > 1:\n",
    "                    tokensplit = token.split()\n",
    "                    for tokensplit_item in tokensplit:\n",
    "                        sentence.append(tokensplit_item)\n",
    "                        label.append(label2id[tag])\n",
    "                else:\n",
    "                    sentence.append(token)\n",
    "                    label.append(label2id[tag])\n",
    "                    label_types.add(tag)\n",
    "        sample = {'text': \" \".join(sentence), 'labels': label}\n",
    "        samples.append(sample)           \n",
    "                    \n",
    "    for sample in samples:\n",
    "        sample['text'] = sample['text'].replace(' ,', ',')\n",
    "        \n",
    "    return samples, label_types\n",
    "\n",
    "def compute_entity_level_f1_score(ground_truths, predictions):\n",
    "    label2id = {'DF': 0, 'NAME': 1, 'O': 2, 'QUANTITY': 3, 'SIZE': 4, 'STATE': 5, 'TEMP': 6, 'UNIT': 7}\n",
    "    id2label = {v: k for k, v in label2id.items()}\n",
    "    statistics = {'tp': 0, 'fn': 0, 'fp': 0}\n",
    "    counting = {k: statistics.copy() for k, v in id2label.items()}\n",
    "    for g, p in zip(ground_truths, predictions):\n",
    "        if g != p:\n",
    "            counting[g]['fn'] += 1\n",
    "            counting[p]['fp'] += 1\n",
    "        else:\n",
    "            counting[g]['tp'] += 1\n",
    "    \n",
    "    recall_precision_f1_score = {}    \n",
    "    for k, v in counting.items():\n",
    "        recall = v['tp'] / (v['tp'] + v['fn']) if v['tp'] + v['fn'] != 0 else 0\n",
    "        precision = v['tp'] / (v['tp'] + v['fp']) if v['tp'] + v['fp'] != 0 else 0\n",
    "        f1_score = 2 * precision * recall / (precision + recall) if precision + recall != 0 else 0\n",
    "        recall_precision_f1_score[k] = {'Recall': recall, 'Precision': precision, 'F1_score': f1_score}\n",
    "    return recall_precision_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfa52e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = ['./train/ar_gk_test.tsv', './train/ar_test.tsv', './train/gk_test.tsv']\n",
    "samples, _ = get_samples(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fac10c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Current test file: ./train/ar_gk_test.tsv\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 2188/2188 [08:12<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'Recall': 0.41836734693877553, 'Precision': 0.4205128205128205, 'F1_score': 0.4194373401534527}, 1: {'Recall': 0.68019747668678, 'Precision': 0.5746061167747915, 'F1_score': 0.6229590555136901}, 2: {'Recall': 0.4921109902067465, 'Precision': 0.611768684477511, 'F1_score': 0.5454545454545455}, 3: {'Recall': 0.6458885941644562, 'Precision': 0.6251604621309371, 'F1_score': 0.6353555120678408}, 4: {'Recall': 0.33653846153846156, 'Precision': 0.3333333333333333, 'F1_score': 0.33492822966507174}, 5: {'Recall': 0.49039341262580055, 'Precision': 0.46568201563857514, 'F1_score': 0.47771836007130125}, 6: {'Recall': 0.27906976744186046, 'Precision': 0.2608695652173913, 'F1_score': 0.2696629213483146}, 7: {'Recall': 0.5717501406865504, 'Precision': 0.6011834319526628, 'F1_score': 0.5860974906259014}}\n",
      "Test Acc: 0.5798673429574717\n",
      "Total Skip: 5\n",
      "\n",
      "\n",
      "Current test file: ./train/ar_test.tsv\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 483/483 [01:47<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'Recall': 0.9607843137254902, 'Precision': 0.98, 'F1_score': 0.9702970297029702}, 1: {'Recall': 0.9765258215962441, 'Precision': 0.9433106575963719, 'F1_score': 0.9596309111880047}, 2: {'Recall': 0.9150779896013865, 'Precision': 0.947935368043088, 'F1_score': 0.9312169312169312}, 3: {'Recall': 0.9963702359346642, 'Precision': 1.0, 'F1_score': 0.9981818181818182}, 4: {'Recall': 1.0, 'Precision': 1.0, 'F1_score': 1.0}, 5: {'Recall': 0.9581993569131833, 'Precision': 0.952076677316294, 'F1_score': 0.9551282051282052}, 6: {'Recall': 0.7, 'Precision': 0.875, 'F1_score': 0.7777777777777777}, 7: {'Recall': 0.9661399548532731, 'Precision': 0.981651376146789, 'F1_score': 0.9738339021615472}}\n",
      "Test Acc: 0.9630550621669627\n",
      "Total Skip: 0\n",
      "\n",
      "\n",
      "Current test file: ./train/gk_test.tsv\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1705/1705 [06:20<00:00,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'Recall': 0.22758620689655173, 'Precision': 0.22758620689655173, 'F1_score': 0.22758620689655173}, 1: {'Recall': 0.5898353614889048, 'Precision': 0.47990681421083287, 'F1_score': 0.5292228644829802}, 2: {'Recall': 0.4132258064516129, 'Precision': 0.53375, 'F1_score': 0.46581818181818174}, 3: {'Recall': 0.5330216247808299, 'Precision': 0.5100671140939598, 'F1_score': 0.5212917976564733}, 4: {'Recall': 0.17857142857142858, 'Precision': 0.17647058823529413, 'F1_score': 0.1775147928994083}, 5: {'Recall': 0.30434782608695654, 'Precision': 0.2840095465393795, 'F1_score': 0.2938271604938272}, 6: {'Recall': 0.15151515151515152, 'Precision': 0.13157894736842105, 'F1_score': 0.14084507042253522}, 7: {'Recall': 0.44111027756939236, 'Precision': 0.4688995215311005, 'F1_score': 0.4545805952841129}}\n",
      "Test Acc: 0.472\n",
      "Total Skip: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import tqdm\n",
    "from nltk.tag.stanford import StanfordNERTagger\n",
    "\n",
    "jar = './stanford-ner.jar'\n",
    "model = './trained_ar.ser.gz' # './trained_ar_gk.ser.gz', './trained_ar.ser.gz', './trained_gk.ser.gz'\n",
    "\n",
    "ner_tagger = StanfordNERTagger(model, jar, encoding='utf8')\n",
    "label2id = {'DF': 0, 'NAME': 1, 'O': 2, 'QUANTITY': 3, 'SIZE': 4, 'STATE': 5, 'TEMP': 6, 'UNIT': 7}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "test_files = ['./train/ar_gk_test.tsv', './train/ar_test.tsv', './train/gk_test.tsv']\n",
    "for test_file in test_files:\n",
    "    print('\\n\\nCurrent test file: {}\\n'.format(test_file))\n",
    "    test_ground_truth_list = []\n",
    "    test_prediction_list = []\n",
    "    samples, _ = get_samples(test_file)\n",
    "    total_skip = 0\n",
    "    for sample in tqdm.tqdm(samples):\n",
    "        text, label = sample['text'], sample['labels']\n",
    "        words = nltk.word_tokenize(text)\n",
    "        output = ner_tagger.tag(words)\n",
    "        prediction = [label2id[pred] for token, pred in output]\n",
    "        if not len(label) == len(prediction): total_skip += 1\n",
    "        test_ground_truth_list.extend(label)\n",
    "        test_prediction_list.extend(prediction)\n",
    "\n",
    "    test_f1_score = compute_entity_level_f1_score(test_ground_truth_list, test_prediction_list)\n",
    "    correct = 0\n",
    "    for p, g in zip(test_prediction_list, test_ground_truth_list):\n",
    "        if p == g: correct += 1\n",
    "    print(test_f1_score)\n",
    "    print('Test Acc: {}'.format(correct / len(test_prediction_list)))\n",
    "    print('Total Skip: {}'.format(total_skip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e940f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Current test file: ./train/ar_gk_test.tsv\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 2188/2188 [10:20<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'Recall': 0.42857142857142855, 'Precision': 0.4329896907216495, 'F1_score': 0.43076923076923074}, 1: {'Recall': 0.6352166758091059, 'Precision': 0.642084835042972, 'F1_score': 0.6386322900868605}, 2: {'Recall': 0.6050054406964092, 'Precision': 0.5840336134453782, 'F1_score': 0.5943345804382685}, 3: {'Recall': 0.6370468611847923, 'Precision': 0.6398756660746003, 'F1_score': 0.638458130261409}, 4: {'Recall': 0.3269230769230769, 'Precision': 0.33663366336633666, 'F1_score': 0.33170731707317075}, 5: {'Recall': 0.48032936870997256, 'Precision': 0.48342541436464087, 'F1_score': 0.48187241854061497}, 6: {'Recall': 0.3488372093023256, 'Precision': 0.3409090909090909, 'F1_score': 0.3448275862068966}, 7: {'Recall': 0.6032639279684862, 'Precision': 0.6287390029325514, 'F1_score': 0.6157380815623205}}\n",
      "Test Acc: 0.6017167381974249\n",
      "Total Skip: 5\n",
      "\n",
      "\n",
      "Current test file: ./train/ar_test.tsv\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 483/483 [02:18<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'Recall': 0.9607843137254902, 'Precision': 0.9423076923076923, 'F1_score': 0.9514563106796117}, 1: {'Recall': 0.9248826291079812, 'Precision': 0.9680589680589681, 'F1_score': 0.9459783913565427}, 2: {'Recall': 0.9618717504332756, 'Precision': 0.7838983050847458, 'F1_score': 0.8638132295719845}, 3: {'Recall': 0.9600725952813067, 'Precision': 1.0, 'F1_score': 0.9796296296296296}, 4: {'Recall': 0.95, 'Precision': 1.0, 'F1_score': 0.9743589743589743}, 5: {'Recall': 0.9228295819935691, 'Precision': 0.959866220735786, 'F1_score': 0.9409836065573771}, 6: {'Recall': 0.9, 'Precision': 1.0, 'F1_score': 0.9473684210526316}, 7: {'Recall': 0.8510158013544018, 'Precision': 0.9792207792207792, 'F1_score': 0.9106280193236714}}\n",
      "Test Acc: 0.9282415630550621\n",
      "Total Skip: 0\n",
      "\n",
      "\n",
      "Current test file: ./train/gk_test.tsv\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1705/1705 [08:10<00:00,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'Recall': 0.2413793103448276, 'Precision': 0.24647887323943662, 'F1_score': 0.24390243902439024}, 1: {'Recall': 0.5468861846814602, 'Precision': 0.5470819906910133, 'F1_score': 0.5469840701628781}, 2: {'Recall': 0.5383870967741935, 'Precision': 0.5383870967741935, 'F1_score': 0.5383870967741935}, 3: {'Recall': 0.5330216247808299, 'Precision': 0.5293093441671504, 'F1_score': 0.5311589982527666}, 4: {'Recall': 0.17857142857142858, 'Precision': 0.18292682926829268, 'F1_score': 0.1807228915662651}, 5: {'Recall': 0.30434782608695654, 'Precision': 0.30241423125794153, 'F1_score': 0.30337794773741233}, 6: {'Recall': 0.18181818181818182, 'Precision': 0.17142857142857143, 'F1_score': 0.1764705882352941}, 7: {'Recall': 0.5213803450862715, 'Precision': 0.5265151515151515, 'F1_score': 0.5239351677346399}}\n",
      "Test Acc: 0.5098\n",
      "Total Skip: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import tqdm\n",
    "from nltk.tag.stanford import StanfordNERTagger\n",
    "\n",
    "jar = './stanford-ner.jar'\n",
    "model = './trained_gk.ser.gz' # './trained_ar_gk.ser.gz', './trained_ar.ser.gz', './trained_gk.ser.gz'\n",
    "\n",
    "ner_tagger = StanfordNERTagger(model, jar, encoding='utf8')\n",
    "label2id = {'DF': 0, 'NAME': 1, 'O': 2, 'QUANTITY': 3, 'SIZE': 4, 'STATE': 5, 'TEMP': 6, 'UNIT': 7}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "test_files = ['./train/ar_gk_test.tsv', './train/ar_test.tsv', './train/gk_test.tsv']\n",
    "for test_file in test_files:\n",
    "    print('\\n\\nCurrent test file: {}\\n'.format(test_file))\n",
    "    test_ground_truth_list = []\n",
    "    test_prediction_list = []\n",
    "    samples, _ = get_samples(test_file)\n",
    "    total_skip = 0\n",
    "    for sample in tqdm.tqdm(samples):\n",
    "        text, label = sample['text'], sample['labels']\n",
    "        words = nltk.word_tokenize(text)\n",
    "        output = ner_tagger.tag(words)\n",
    "        prediction = [label2id[pred] for token, pred in output]\n",
    "        if not len(label) == len(prediction): total_skip += 1\n",
    "        test_ground_truth_list.extend(label)\n",
    "        test_prediction_list.extend(prediction)\n",
    "\n",
    "    test_f1_score = compute_entity_level_f1_score(test_ground_truth_list, test_prediction_list)\n",
    "    correct = 0\n",
    "    for p, g in zip(test_prediction_list, test_ground_truth_list):\n",
    "        if p == g: correct += 1\n",
    "    print(test_f1_score)\n",
    "    print('Test Acc: {}'.format(correct / len(test_prediction_list)))\n",
    "    print('Total Skip: {}'.format(total_skip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb7b1d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Current test file: ./train/ar_gk_test.tsv\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 2188/2188 [10:44<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'Recall': 0.42346938775510207, 'Precision': 0.43005181347150256, 'F1_score': 0.4267352185089974}, 1: {'Recall': 0.6453647833241909, 'Precision': 0.6448342011510003, 'F1_score': 0.6450993831391364}, 2: {'Recall': 0.6006528835690969, 'Precision': 0.5978878960194963, 'F1_score': 0.5992672004342515}, 3: {'Recall': 0.6436781609195402, 'Precision': 0.6422584913983238, 'F1_score': 0.642967542503864}, 4: {'Recall': 0.3269230769230769, 'Precision': 0.3333333333333333, 'F1_score': 0.3300970873786408}, 5: {'Recall': 0.4876486733760293, 'Precision': 0.48498635122838946, 'F1_score': 0.4863138686131387}, 6: {'Recall': 0.3488372093023256, 'Precision': 0.3333333333333333, 'F1_score': 0.3409090909090909}, 7: {'Recall': 0.6268992684299382, 'Precision': 0.6369353916523728, 'F1_score': 0.6318774815655134}}\n",
      "Test Acc: 0.6083495903238393\n",
      "Total Skip: 5\n",
      "\n",
      "\n",
      "Current test file: ./train/ar_test.tsv\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 483/483 [02:23<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'Recall': 0.9411764705882353, 'Precision': 0.9411764705882353, 'F1_score': 0.9411764705882353}, 1: {'Recall': 0.9624413145539906, 'Precision': 0.9738717339667459, 'F1_score': 0.9681227863046045}, 2: {'Recall': 0.9601386481802426, 'Precision': 0.8878205128205128, 'F1_score': 0.9225645295587012}, 3: {'Recall': 0.9872958257713249, 'Precision': 1.0, 'F1_score': 0.993607305936073}, 4: {'Recall': 0.95, 'Precision': 1.0, 'F1_score': 0.9743589743589743}, 5: {'Recall': 0.9453376205787781, 'Precision': 0.9735099337748344, 'F1_score': 0.9592169657422512}, 6: {'Recall': 0.9, 'Precision': 1.0, 'F1_score': 0.9473684210526316}, 7: {'Recall': 0.945823927765237, 'Precision': 0.9882075471698113, 'F1_score': 0.9665513264129182}}\n",
      "Test Acc: 0.9616341030195382\n",
      "Total Skip: 0\n",
      "\n",
      "\n",
      "Current test file: ./train/gk_test.tsv\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1705/1705 [08:24<00:00,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'Recall': 0.2413793103448276, 'Precision': 0.24647887323943662, 'F1_score': 0.24390243902439024}, 1: {'Recall': 0.5486757337151038, 'Precision': 0.5461346633416458, 'F1_score': 0.5474022495982861}, 2: {'Recall': 0.5335483870967742, 'Precision': 0.5389377647442164, 'F1_score': 0.5362295347706275}, 3: {'Recall': 0.5330216247808299, 'Precision': 0.5293093441671504, 'F1_score': 0.5311589982527666}, 4: {'Recall': 0.17857142857142858, 'Precision': 0.18072289156626506, 'F1_score': 0.17964071856287425}, 5: {'Recall': 0.30562659846547313, 'Precision': 0.2998745294855709, 'F1_score': 0.3027232425585814}, 6: {'Recall': 0.18181818181818182, 'Precision': 0.16666666666666666, 'F1_score': 0.17391304347826086}, 7: {'Recall': 0.5213803450862715, 'Precision': 0.5245283018867924, 'F1_score': 0.5229495861550038}}\n",
      "Test Acc: 0.5089\n",
      "Total Skip: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import tqdm\n",
    "from nltk.tag.stanford import StanfordNERTagger\n",
    "\n",
    "jar = './stanford-ner.jar'\n",
    "model = './trained_ar_gk.ser.gz' # './trained_ar_gk.ser.gz', './trained_ar.ser.gz', './trained_gk.ser.gz'\n",
    "\n",
    "ner_tagger = StanfordNERTagger(model, jar, encoding='utf8')\n",
    "label2id = {'DF': 0, 'NAME': 1, 'O': 2, 'QUANTITY': 3, 'SIZE': 4, 'STATE': 5, 'TEMP': 6, 'UNIT': 7}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "test_files = ['./train/ar_gk_test.tsv', './train/ar_test.tsv', './train/gk_test.tsv']\n",
    "for test_file in test_files:\n",
    "    print('\\n\\nCurrent test file: {}\\n'.format(test_file))\n",
    "    test_ground_truth_list = []\n",
    "    test_prediction_list = []\n",
    "    samples, _ = get_samples(test_file)\n",
    "    total_skip = 0\n",
    "    for sample in tqdm.tqdm(samples):\n",
    "        text, label = sample['text'], sample['labels']\n",
    "        words = nltk.word_tokenize(text)\n",
    "        output = ner_tagger.tag(words)\n",
    "        prediction = [label2id[pred] for token, pred in output]\n",
    "        if not len(label) == len(prediction): total_skip += 1\n",
    "        test_ground_truth_list.extend(label)\n",
    "        test_prediction_list.extend(prediction)\n",
    "\n",
    "    test_f1_score = compute_entity_level_f1_score(test_ground_truth_list, test_prediction_list)\n",
    "    correct = 0\n",
    "    for p, g in zip(test_prediction_list, test_ground_truth_list):\n",
    "        if p == g: correct += 1\n",
    "    print(test_f1_score)\n",
    "    print('Test Acc: {}'.format(correct / len(test_prediction_list)))\n",
    "    print('Total Skip: {}'.format(total_skip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17c3b78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
